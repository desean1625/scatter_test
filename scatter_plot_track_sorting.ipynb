{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desean1625/scatter_test/blob/main/scatter_plot_track_sorting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOeaNoS2oC8g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from numpy.random import default_rng\n",
        "\n",
        "total_points = 1000 #Total number of points generated \n",
        "limits = [[-10,10],[-10,10]] #x/y limits for data generation\n",
        "number_of_possible_clusters = 5 \n",
        "add_random_noise = True #hopefully the model will filter the noise from the clusters\n",
        "batch_size = 32 \n",
        "randomize_points = True #randomizes the points array so they aren't sequential\n",
        "ranomization_level = .1 #percent of the array we ar going to shuffle\n",
        "\n",
        "\n",
        "total = total_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYx3m8juoC8h"
      },
      "outputs": [],
      "source": [
        "def conv_block(fs, x, activation = 'relu'):\n",
        "  conv  = layers.Conv2D(fs, (3, 3), padding = 'same', activation = activation)(x)\n",
        "  bnrm  = layers.BatchNormalization()(conv)\n",
        "  drop  = layers.Dropout(0.5)(bnrm)\n",
        "  return drop\n",
        "\n",
        "def residual_block(fs, x):\n",
        "  y = conv_block(fs, x)\n",
        "  y = conv_block(fs, y)\n",
        "  y = conv_block(fs, y)\n",
        "  return layers.Concatenate(axis = -1)([x, y])\n",
        "\n",
        "inp = keras.Input(shape = (total,2))\n",
        "out = inp\n",
        "out = layers.Concatenate(axis=1)([out, out,out])\n",
        "out = layers.Reshape((3,total,2))(out)\n",
        "out = residual_block(16, out) #create convolutional filters\n",
        "out  = layers.MaxPooling2D(pool_size = (2, 2))(out)\n",
        "out = residual_block(16, out) #create convolutional filters\n",
        "out = layers.Dense(32)(out)\n",
        "out = layers.Dense(8)(out)\n",
        "out = layers.Dense(4)(out)\n",
        "out = layers.Dense(2)(out)\n",
        "out = layers.Dense(1)(out)\n",
        "out = layers.Flatten()(out)\n",
        "out = layers.Dense(total)(out) #prediction layer output for every input point\n",
        "model = keras.models.Model(inputs = inp, outputs = out)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8CqiyXjoC8y"
      },
      "outputs": [],
      "source": [
        "#Create training data generator\n",
        "import math\n",
        "import random\n",
        "\n",
        "def rng_swap(a,i):\n",
        "    rng = random.randint(0,len(a)-1)\n",
        "    a[i],a[rng] = a[rng],a[i]\n",
        "def shuffle(a,swap_chance):\n",
        "    for i in range(len(a)):\n",
        "        if random.random()<0.1:\n",
        "           rng_swap(a,i)\n",
        "\n",
        "def generate_random_path(x,y,length,heading_std=.01,speed_start=.01,speed_std=.01):\n",
        "    global limits\n",
        "    points = []\n",
        "    points.append([x,y])\n",
        "\n",
        "    heading = random.uniform(0,360)\n",
        "    speed = speed_start\n",
        "\n",
        "    for i in range(0,length-1):\n",
        "        heading = heading + random.gauss(0,heading_std)\n",
        "        heading = heading % 360\n",
        "        x1 = points[i][0]+ math.cos(math.radians(heading))*speed\n",
        "        y1 = points[i][1]+ math.sin(math.radians(heading))*speed\n",
        "        if x1<limits[0][0]: x1=limits[0][0]\n",
        "        if x1>limits[0][1]: x1=limits[0][1]\n",
        "        if y1<limits[1][0]: y1=limits[1][0]\n",
        "        if y1>limits[1][1]: y1=limits[1][1]\n",
        "        points.append([x1,y1])\n",
        "        speed = speed + random.gauss(0,speed_std)\n",
        "    return points\n",
        "\n",
        "def norm(xy):\n",
        "  global limits\n",
        "  x_range = limits[0]\n",
        "  y_range = limits[1]\n",
        "  x = (xy[0]-x_range[0])/(x_range[1]-x_range[0])\n",
        "  y = (xy[1]-y_range[0])/(y_range[1]-y_range[0])\n",
        "  return (x,y)\n",
        "def rand_point(x,y):\n",
        "  deviation = .01\n",
        "  xmin = x -(x*deviation)\n",
        "  xmax = x + (x*deviation)\n",
        "  ymin = y -(y*deviation)\n",
        "  ymax = y + (y*deviation)\n",
        "  x = random.uniform(xmin, xmax)\n",
        "  y = random.uniform(ymin, ymax)\n",
        "  return x,y\n",
        "def create_sample(total,randomize_points=True):\n",
        "  global limits\n",
        "  global ranomization_level\n",
        "  global add_random_noise\n",
        "  clusters = random.randint(2,6)\n",
        "  num = int((total)//clusters)\n",
        "  allx =[]\n",
        "  ally = []\n",
        "  for x in range(1,clusters+1):\n",
        "    n = (random.uniform(*limits[0]),random.uniform(*limits[1]))\n",
        "    points = generate_random_path(n[0],n[1],num)\n",
        "    allx.extend(points)\n",
        "    for i in range(0,num):\n",
        "      ally.append(x)\n",
        "    if x == clusters and total-len(allx) != 0:\n",
        "      #top up the remainder\n",
        "      points = generate_random_path(allx[len(allx)-1][0],allx[len(allx)-1][1],total-len(allx))\n",
        "      allx.extend(points)\n",
        "      for z in range(0,total-len(ally)):\n",
        "        ally.append(x)\n",
        "  if add_random_noise:\n",
        "    rng = default_rng()\n",
        "    numbers = rng.choice(len(allx), size=int(len(allx)*ranomization_level), replace=False)\n",
        "    for i in numbers:\n",
        "      n = (random.uniform(*limits[0]),random.uniform(*limits[1]))\n",
        "      allx[i] =n\n",
        "      ally[i] = 0\n",
        "  normx = list(map(norm,allx))\n",
        "  x = np.array([np.hstack(t) for t in normx],dtype=np.float32)\n",
        "  y = np.array(ally,dtype=np.float32)\n",
        "  if randomize_points:\n",
        "    z = list(zip(x,y))\n",
        "    shuffle(z,.1)\n",
        "    x,y = zip(*z)\n",
        "  return x,y\n",
        "def train_gen(total,batch_size=32,randomize_points=True):\n",
        "  while True:\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    for x in range(0,batch_size):\n",
        "      x,y = create_sample(total,randomize_points)\n",
        "      x_train.append(x)      \n",
        "      y_train.append(y)\n",
        "    yield np.array(x_train),np.array(y_train)\n",
        "gen = train_gen(total,batch_size,randomize_points)\n",
        "x_train,y_train = next(gen)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001\n",
        ")\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "    # calculating difference between target and predicted values \n",
        "    loss = keras.backend.abs(y_true - y_pred)   # (batch_size, 2)\n",
        "    loss = loss * 1.5          # Make the penalty for being wrong more severe      \n",
        "    # summing both loss values along batch dimension \n",
        "    loss = keras.backend.sum(loss, axis=1)       \n",
        "    return loss\n",
        "loss = custom_loss\n",
        "\n",
        "\n",
        "def total_accuracy(y_true, y_pred):\n",
        "    equals = (y_true.numpy().flatten() == keras.backend.round(y_pred).numpy().flatten()).sum()  #TODO fix this to use tf functions instead of numpy so we don't need to run_eagerly\n",
        "    result = equals/len(y_pred.numpy().flatten())\n",
        "    return result\n",
        "loss = custom_loss\n",
        "model.compile(loss=loss, optimizer=opt, metrics=[total_accuracy], run_eagerly=True)"
      ],
      "metadata": {
        "id": "5ufZhI4rDW55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_patience = 15\n",
        "#early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"total_accuracy\",patience=early_stopping_patience,restore_best_weights=True)\n",
        "#model.fit(gen,steps_per_epoch=batch_size, epochs=2000,callbacks=[early_stopping])\n",
        "model.fit(gen,steps_per_epoch=batch_size, epochs=2000)"
      ],
      "metadata": {
        "id": "NleAVG-4DnGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train = next(gen)\n",
        "\n",
        "r = keras.backend.round(model.predict(x_train))\n",
        "print(\"players found\",len(np.unique(r.numpy()[0])))\n",
        "print(\"players expected\",len(np.unique(y_train[0])))\n",
        "print(\"predicted\",r.numpy()[0][0:10])\n",
        "print(\"expected\", y_train[0][0:10])\n",
        "equals = (r.numpy()[0] == y_train[0]).sum()  \n",
        "result = equals/len(y_train[0])\n",
        "print(\"Prediction accuracy\",result)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x_train[0][:, 0],x_train[0][:, 1],c=y_train[0])\n",
        "plt.show()\n",
        "plt.scatter(x_train[0][:, 0],x_train[0][:, 1],c=r.numpy()[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6uZBhCBmaPXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x_train[0][:, 0],x_train[0][:, 1],c=y_train[0])\n",
        "plt.show()\n",
        "plt.scatter(x_train[0][:, 0],x_train[0][:, 1],c=r.numpy()[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QUwgoiFQB2YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import default_rng\n",
        "\n",
        "rng = default_rng()\n",
        "numbers = rng.choice(20, size=10, replace=False)\n",
        "print(numbers)"
      ],
      "metadata": {
        "id": "Ajoc_pTb_r45"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}