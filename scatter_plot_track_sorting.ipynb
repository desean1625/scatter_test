{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desean1625/scatter_test/blob/main/scatter_plot_track_sorting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOeaNoS2oC8g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "total = 10000\n",
        "batch_size = 10 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYx3m8juoC8h"
      },
      "outputs": [],
      "source": [
        "def conv_block(fs, x, activation = 'relu'):\n",
        "  conv  = layers.Conv2D(fs, (3, 3), padding = 'same', activation = activation)(x)\n",
        "  bnrm  = layers.BatchNormalization()(conv)\n",
        "  drop  = layers.Dropout(0.5)(bnrm)\n",
        "  return drop\n",
        "\n",
        "def residual_block(fs, x):\n",
        "  y = conv_block(fs, x)\n",
        "  y = conv_block(fs, y)\n",
        "  y = conv_block(fs, y)\n",
        "  return layers.Concatenate(axis = -1)([x, y])\n",
        "\n",
        "inp = keras.Input(shape = (total,2))\n",
        "out = layers.Dropout(.05)(inp)\n",
        "out = layers.Concatenate(axis=1)([out, out,out])\n",
        "out = layers.Reshape((3,32,625))(out)\n",
        "out = residual_block(16, out) #create convolutional filters\n",
        "out = layers.Dense(2048)(out)\n",
        "out = layers.Dense(1024)(out)\n",
        "out = layers.Dense(256)(out)\n",
        "out = layers.Flatten()(out)\n",
        "out = layers.Dense(total)(out) #prediction layer output for every input point\n",
        "model = keras.models.Model(inputs = inp, outputs = out)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8CqiyXjoC8y"
      },
      "outputs": [],
      "source": [
        "#Create training data generator\n",
        "def norm(xy):\n",
        "  x_range = (-180,180)\n",
        "  y_range = (-90,90)\n",
        "  x = (xy[0]-x_range[0])/(x_range[1]-x_range[0])\n",
        "  y = (xy[1]-y_range[0])/(y_range[1]-y_range[0])\n",
        "  return (x,y)\n",
        "def rand_point(x,y):\n",
        "  deviation = .01\n",
        "  xmin = x -(x*deviation)\n",
        "  xmax = x + (x*deviation)\n",
        "  ymin = y -(y*deviation)\n",
        "  ymax = y + (y*deviation)\n",
        "  x = random.uniform(xmin, xmax)\n",
        "  y = random.uniform(ymin, ymax)\n",
        "  return x,y\n",
        "def create_sample(total):\n",
        "  clusters = random.randint(0,4)\n",
        "  num = total//(clusters+1)\n",
        "  allx =[]\n",
        "  ally = []\n",
        "  for x in range(1,clusters+1):\n",
        "    n = (random.uniform(-180,180),random.uniform(-90,90))\n",
        "    for z in range(0,num):\n",
        "      allx.append(rand_point(n[0],n[1]))\n",
        "      ally.append(x)\n",
        "  for n in range(0,total-len(allx)):\n",
        "    n = (random.uniform(-180,180),random.uniform(-90,90))\n",
        "    allx.append(n)\n",
        "    ally.append(0)\n",
        "  normx = list(map(norm,allx))\n",
        "  x = np.array([np.hstack(t) for t in normx],dtype=np.float32)\n",
        "  y = np.array(ally,dtype=np.float32)\n",
        "  return x,y\n",
        "def train_gen(total,batch_size=32):\n",
        "  while True:\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    for x in range(0,batch_size):\n",
        "      x,y = create_sample(total)\n",
        "      x_train.append(x)      \n",
        "      y_train.append(y)\n",
        "    yield np.array(x_train),np.array(y_train)\n",
        "gen = train_gen(total,batch_size)\n",
        "x_train,y_train = next(gen)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0001\n",
        ")\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "    # calculating difference between target and predicted values \n",
        "    loss = keras.backend.abs(y_true - y_pred)   # (batch_size, 2)\n",
        "    loss = loss * 1.5          # Make the penalty for being wrong more severe      \n",
        "    # summing both loss values along batch dimension \n",
        "    loss = keras.backend.sum(loss, axis=1)       \n",
        "    return loss\n",
        "loss = custom_loss\n",
        "\n",
        "\n",
        "def my_acc_fn(y_true, y_pred):\n",
        "    equals = (y_true.numpy().flatten() == keras.backend.round(y_pred).numpy().flatten()).sum()  #TODO fix this to use tf functions instead of numpy so we don't need to run_eagerly\n",
        "    result = equals/len(y_pred.numpy().flatten())\n",
        "    return result\n",
        "loss = custom_loss\n",
        "model.compile(loss=loss, optimizer=opt, metrics=[my_acc_fn], run_eagerly=True)"
      ],
      "metadata": {
        "id": "5ufZhI4rDW55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(gen,steps_per_epoch=batch_size//1, epochs=2000)"
      ],
      "metadata": {
        "id": "NleAVG-4DnGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train = next(gen)\n",
        "\n",
        "r = keras.backend.round(model.predict(x_train))\n",
        "print(r.numpy()[0].max())\n",
        "print(r.numpy()[0][0:10])\n",
        "print(y_train[0][0:10])\n",
        "equals = (r.numpy()[0] == y_train[0]).sum()  \n",
        "result = equals/len(y_train[0])\n",
        "print(result)"
      ],
      "metadata": {
        "id": "6uZBhCBmaPXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x_train[0][:, 0],x_train[0][:, 1],c=y_train[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QUwgoiFQB2YR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}